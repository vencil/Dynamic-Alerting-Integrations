#!/usr/bin/env python3
"""migrate_rule.py â€” å‚³çµ± Prometheus è­¦å ±è¦å‰‡é·ç§»è¼”åŠ©å·¥å…· (v2)ã€‚

è‡ªå‹•å°‡å‚³çµ±çš„ PromQL (å¯«æ­»æ•¸å€¼) è½‰æ›ç‚ºæœ¬å°ˆæ¡ˆçš„ã€Œå‹•æ…‹å¤šç§Ÿæˆ¶ã€ä¸‰ä»¶å¥—ï¼š
1. Tenant ConfigMap YAML    â†’ migration_output/tenant-config.yaml
2. å¹³å° Recording Rule      â†’ migration_output/platform-recording-rules.yaml
3. å¹³å°å‹•æ…‹ Alert Rule      â†’ migration_output/platform-alert-rules.yaml
4. é·ç§»å ±å‘Š                 â†’ migration_output/migration-report.txt

ç”¨æ³•:
  python3 migrate_rule.py <legacy_rules.yml>                    # é è¨­æª”æ¡ˆè¼¸å‡º
  python3 migrate_rule.py <legacy_rules.yml> --dry-run          # åƒ…é¡¯ç¤ºå ±å‘Šï¼Œä¸ç”¢ç”Ÿæª”æ¡ˆ
  python3 migrate_rule.py <legacy_rules.yml> --interactive      # é‡åˆ°ä¸ç¢ºå®šæ™‚è©¢å•ä½¿ç”¨è€…
  python3 migrate_rule.py <legacy_rules.yml> -o /custom/path    # è‡ªè¨‚è¼¸å‡ºç›®éŒ„

Phase 3A å‡ç´š:
  - æ™ºèƒ½èšåˆçŒœæ¸¬ (Heuristics): è‡ªå‹•åˆ¤æ–· sum/maxï¼Œæ¸›å°‘ 90%+ äººå·¥ä»‹å…¥
  - æª”æ¡ˆåŒ–è¼¸å‡º: åˆ†é›¢çš„ YAML æª”æ¡ˆï¼Œå¯ç›´æ¥ kubectl apply
  - --dry-run: é è¦½æ¨¡å¼
  - --interactive: äº’å‹•ç¢ºèªæ¨¡å¼
"""

import sys
import re
import os
import argparse
import yaml


# ============================================================
# Heuristics: æ™ºèƒ½èšåˆçŒœæ¸¬
# ============================================================

def guess_aggregation(base_key, expr_str):
    """æ ¹æ“š metric åç¨±å’Œ PromQL è¡¨é”å¼æ™ºèƒ½çŒœæ¸¬èšåˆæ¨¡å¼ã€‚

    å›å‚³: (mode, reason) â€” mode ç‚º "sum" æˆ– "max"ï¼Œreason ç‚ºæ¨ç†èªªæ˜ã€‚
    """
    expr_lower = expr_str.lower()
    key_lower = base_key.lower()

    # Rule 1: rate() / increase() / irate() â†’ sum (å¢é›†ç¸½é‡)
    if re.search(r'\b(rate|increase|irate)\s*\(', expr_lower):
        return "sum", "åŒ…å« rate/increase â€” å¢é›†èšåˆç¸½é‡"

    # Rule 2: _total å¾Œç¶´ (Prometheus counter å‘½åæ…£ä¾‹) â†’ sum
    if key_lower.endswith('_total'):
        return "sum", "Counter å‘½åæ…£ä¾‹ (_total) â€” å¢é›†èšåˆç¸½é‡"

    # Rule 3: åŒ…å«ç™¾åˆ†æ¯”/æ¯”ç‡/å»¶é²/è½å¾Œ â†’ max (æœ€å¼±ç’°ç¯€)
    ratio_keywords = ('percent', 'ratio', 'lag', 'latency', 'delay',
                      'utilization', 'usage', 'saturation')
    for kw in ratio_keywords:
        if kw in key_lower:
            return "max", f"é—œéµå­— '{kw}' â€” æœ€å¼±ç’°ç¯€ (å–®é»ç“¶é ¸)"

    # Rule 4: åŒ…å« total/bytes/count â†’ sum (ç´¯ç©é‡)
    sum_keywords = ('total', 'bytes', 'count', 'size', 'sent', 'received',
                    'evicted', 'expired', 'rejected', 'errors', 'requests')
    for kw in sum_keywords:
        if kw in key_lower:
            return "sum", f"é—œéµå­— '{kw}' â€” å¢é›†ç´¯ç©é‡"

    # Rule 5: åŒ…å«é™¤æ³• â†’ max (é€šå¸¸æ˜¯ ratio/percent è¨ˆç®—)
    if '/' in expr_str:
        return "max", "åŒ…å«é™¤æ³•é‹ç®— â€” é€šå¸¸ç‚ºæ¯”ç‡è¨ˆç®—"

    # Rule 6: é€£ç·šæ•¸ã€ä½‡åˆ—é•·åº¦ç­‰ â†’ max (å–®é»ä¸Šé™)
    max_keywords = ('connections', 'connected', 'clients', 'threads',
                    'queue', 'replication', 'slave', 'replica')
    for kw in max_keywords:
        if kw in key_lower:
            return "max", f"é—œéµå­— '{kw}' â€” å–®é»ä¸Šé™"

    # Fallback â†’ max (ä¿éšœå–®é»å®‰å…¨)
    return "max", "é è¨­ Fallback â€” ä¿éšœå–®é»å®‰å…¨"


# ============================================================
# PromQL è§£æå™¨
# ============================================================

# èªç¾©ä¸å¯è½‰æ›çš„ PromQL å‡½å¼
SEMANTIC_BREAK_FUNCS = frozenset({
    'absent', 'absent_over_time', 'vector', 'scalar',
    'predict_linear', 'holt_winters', 'label_replace', 'label_join'
})

# PromQL å…§å»ºå‡½å¼/é—œéµå­— (ç”¨æ–¼è·³éï¼Œæ‰¾åˆ°çœŸæ­£çš„ metric åç¨±)
PROMQL_FUNCS = frozenset({
    'abs', 'absent', 'absent_over_time', 'avg', 'avg_over_time',
    'ceil', 'changes', 'clamp', 'clamp_max', 'clamp_min', 'count',
    'count_over_time', 'day_of_month', 'day_of_week', 'days_in_month',
    'delta', 'deriv', 'exp', 'floor', 'group', 'histogram_quantile',
    'holt_winters', 'hour', 'idelta', 'increase', 'irate', 'label_join',
    'label_replace', 'last_over_time', 'ln', 'log2', 'log10', 'max',
    'max_over_time', 'min', 'min_over_time', 'minute', 'month',
    'predict_linear', 'quantile', 'quantile_over_time', 'rate', 'resets',
    'round', 'scalar', 'sgn', 'sort', 'sort_desc', 'sqrt', 'stddev',
    'stddev_over_time', 'stdvar', 'stdvar_over_time', 'sum',
    'sum_over_time', 'time', 'timestamp', 'vector', 'year',
    'by', 'without', 'on', 'ignoring', 'group_left', 'group_right', 'bool',
})


def extract_label_matchers(expr_str):
    """å¾ PromQL è¡¨é”å¼ä¸­æå– label matchers (å¦‚ {queue="tasks", db="0"})ã€‚

    å›å‚³: list of dictï¼Œæ¯å€‹ dict = {"metric": str, "labels": dict}
    ç”¨æ–¼ Phase 2B ç¶­åº¦æ¨™ç±¤æç¤ºã€‚
    """
    results = []
    pattern = re.compile(r'([a-zA-Z_][a-zA-Z0-9_]*)\{([^}]+)\}')
    for m in pattern.finditer(expr_str):
        metric = m.group(1)
        labels_str = m.group(2)
        labels = {}
        for pair in re.finditer(r'([a-zA-Z_][a-zA-Z0-9_]*)\s*(!?=~?)\s*"([^"]*)"', labels_str):
            lk, op, lv = pair.group(1), pair.group(2), pair.group(3)
            if lk in ('job', 'instance', '__name__', 'namespace', 'pod', 'container'):
                continue
            if op != '=':
                continue
            labels[lk] = lv
        if labels:
            results.append({"metric": metric, "labels": labels})
    return results


def parse_expr(expr_str):
    """è§£æ PromQL è¡¨é”å¼ï¼Œå˜—è©¦åˆ‡åˆ†ç‚º LHS, Operator, RHS (é–¾å€¼æ•¸å€¼)ã€‚"""
    match = re.match(
        r'^\s*(.*?)\s*(==|!=|>=|<=|>|<)\s*([0-9.]+(?:[eE][+-]?[0-9]+)?)\s*$',
        expr_str
    )
    if not match:
        return None

    lhs, op, rhs = match.groups()

    # èªç¾©ä¸å¯è½‰æ›çš„å‡½å¼ â†’ äº¤ç”± LLM Fallback
    first_func = re.match(r'\s*([a-zA-Z_]+)\s*\(', lhs)
    if first_func and first_func.group(1) in SEMANTIC_BREAK_FUNCS:
        return None

    is_complex = bool(re.search(r'[\(\)\[\]/+\-*]', lhs))

    # æå–çœŸæ­£çš„ metric åç¨± (è·³éå‡½å¼å)
    base_key = "unknown_metric"
    for m in re.finditer(r'([a-zA-Z_][a-zA-Z0-9_]*)', lhs):
        if m.group(1) not in PROMQL_FUNCS:
            base_key = m.group(1)
            break

    return {
        "lhs": lhs.strip(),
        "op": op,
        "val": rhs,
        "is_complex": is_complex,
        "base_key": base_key,
    }


# ============================================================
# Rule è™•ç†æ ¸å¿ƒ
# ============================================================

class MigrationResult:
    """å–®æ¢è¦å‰‡çš„é·ç§»çµæœã€‚"""

    def __init__(self, alert_name, status, severity="warning"):
        self.alert_name = alert_name
        self.status = status  # "perfect" | "complex" | "unparseable"
        self.severity = severity

        # ä¸‰ä»¶å¥—å…§å®¹
        self.tenant_config = {}       # {metric_key: value}
        self.recording_rules = []     # list of dict (YAML-ready)
        self.alert_rules = []         # list of dict (YAML-ready)

        # å ±å‘Šé™„åŠ è³‡è¨Š
        self.agg_mode = None
        self.agg_reason = None
        self.dim_hints = []
        self.llm_prompt = None
        self.notes = []


def process_rule(rule, interactive=False):
    """è™•ç†å–®æ¢å‚³çµ± Prometheus è¦å‰‡ï¼Œå›å‚³ MigrationResultã€‚"""
    alert_name = rule.get('alert')
    if not alert_name:
        return None

    expr = rule.get('expr', '')
    severity = rule.get('labels', {}).get('severity', 'warning')
    parsed = parse_expr(expr)

    # æƒ…å¢ƒ 3: ç„¡æ³•è§£æ
    if not parsed:
        result = MigrationResult(alert_name, "unparseable", severity)
        result.llm_prompt = (
            f"è«‹å°‡ä»¥ä¸‹å‚³çµ± Prometheus Alert è½‰æ›ç‚ºæœ¬å°ˆæ¡ˆçš„å‹•æ…‹å¤šç§Ÿæˆ¶æ¶æ§‹ï¼š\n"
            f"è¦æ±‚ï¼š\n"
            f"1. æå–é–¾å€¼ä¸¦æä¾› threshold-config.yaml ç¯„ä¾‹ã€‚\n"
            f"2. æä¾›åŒ…å« sum/max by(tenant) çš„ Recording Ruleã€‚\n"
            f"3. æä¾›å¥—ç”¨ group_left èˆ‡ unless maintenance é‚è¼¯çš„ Alert Ruleã€‚\n"
            f"4. å¦‚æœ‰ç¶­åº¦æ¨™ç±¤ (å¦‚ queue, db, index)ï¼Œè«‹ç”¨ \"metric{{label=\\\"value\\\"}}\" èªæ³•æä¾›ç¯„ä¾‹ã€‚\n\n"
            f"åŸå§‹è¦å‰‡ï¼š\n{yaml.dump([rule], sort_keys=False)}"
        )
        return result

    metric_key = parsed["base_key"]
    metric_key_yaml = f"{metric_key}_critical" if severity == "critical" else metric_key

    # æ™ºèƒ½çŒœæ¸¬èšåˆæ¨¡å¼
    agg_mode, agg_reason = guess_aggregation(parsed["base_key"], parsed["lhs"])

    # äº’å‹•æ¨¡å¼: è¤‡é›œè¡¨é”å¼æ™‚è©¢å•ä½¿ç”¨è€…
    if interactive and parsed["is_complex"]:
        print(f"\nğŸ” Alert: {alert_name}")
        print(f"   Expr: {expr}")
        print(f"   ğŸ¤– AI çŒœæ¸¬: {agg_mode} ({agg_reason})")
        choice = input(f"   é¸æ“‡èšåˆæ¨¡å¼ [s=sum / m=max / Enter=æ¡ç”¨çŒœæ¸¬]: ").strip().lower()
        if choice == 's':
            agg_mode = "sum"
            agg_reason = "ä½¿ç”¨è€…æ‰‹å‹•é¸æ“‡"
        elif choice == 'm':
            agg_mode = "max"
            agg_reason = "ä½¿ç”¨è€…æ‰‹å‹•é¸æ“‡"

    status = "complex" if parsed["is_complex"] else "perfect"
    result = MigrationResult(alert_name, status, severity)
    result.agg_mode = agg_mode
    result.agg_reason = agg_reason

    # ç¶­åº¦æ¨™ç±¤æç¤º
    result.dim_hints = extract_label_matchers(expr)

    # === ç”¢å‡º 1. Tenant Config ===
    result.tenant_config[metric_key_yaml] = parsed['val']

    # === ç”¢å‡º 2. Recording Rules ===
    result.recording_rules.append({
        "record": f"tenant:{metric_key}:{agg_mode}",
        "expr": f"{agg_mode} by(tenant) ({parsed['lhs']})",
    })
    result.recording_rules.append({
        "record": f"tenant:alert_threshold:{metric_key}",
        "expr": f'sum by(tenant) (user_threshold{{metric="{metric_key}", severity="{severity}"}})',
    })

    # === ç”¢å‡º 3. Alert Rule ===
    alert_rule = {
        "alert": alert_name,
        "expr": (
            f"(\n"
            f"  tenant:{metric_key}:{agg_mode}\n"
            f"  {parsed['op']} on(tenant) group_left\n"
            f"  tenant:alert_threshold:{metric_key}\n"
            f")\n"
            f'unless on(tenant) (user_state_filter{{filter="maintenance"}} == 1)'
        ),
    }
    if 'for' in rule:
        alert_rule['for'] = rule['for']
    if 'labels' in rule:
        alert_rule['labels'] = rule['labels']
    if 'annotations' in rule:
        alert_rule['annotations'] = rule['annotations']
    result.alert_rules.append(alert_rule)

    return result


# ============================================================
# è¼¸å‡ºå¼•æ“
# ============================================================

def write_outputs(results, output_dir):
    """å°‡é·ç§»çµæœå¯«å…¥åˆ†é›¢çš„ YAML æª”æ¡ˆã€‚"""
    os.makedirs(output_dir, exist_ok=True)

    # --- tenant-config.yaml ---
    tenant_configs = {}
    for r in results:
        if r.status == "unparseable":
            continue
        for k, v in r.tenant_config.items():
            tenant_configs[k] = f'"{v}"'

    tenant_yaml = {
        "# å°‡ä»¥ä¸‹ key-value è¤‡è£½åˆ°å°æ‡‰çš„ tenant YAML (å¦‚ db-a.yaml)": None,
        "# ç¯„ä¾‹: tenants.db-a å€å¡Šä¸­åŠ å…¥é€™äº› key": None,
    }
    # Write as plain YAML-ready snippets
    with open(os.path.join(output_dir, "tenant-config.yaml"), 'w', encoding='utf-8') as f:
        f.write("# ============================================================\n")
        f.write("# Tenant Config â€” è¤‡è£½åˆ° conf.d/<tenant>.yaml çš„ tenants å€å¡Š\n")
        f.write("# ============================================================\n")
        f.write("# ç¯„ä¾‹:\n")
        f.write("# tenants:\n")
        f.write("#   db-a:\n")
        for k, v in tenant_configs.items():
            f.write(f"#     {k}: {v}\n")
        f.write("#\n")
        f.write("# ä»¥ä¸‹ç‚ºå„è¦å‰‡æå–çš„é–¾å€¼:\n\n")
        for r in results:
            if r.status == "unparseable":
                continue
            f.write(f"# --- From: {r.alert_name} (severity: {r.severity}) ---\n")
            for k, v in r.tenant_config.items():
                f.write(f"{k}: \"{v}\"\n")
            if r.dim_hints:
                f.write("# ğŸ“ ç¶­åº¦æ¨™ç±¤æ›¿ä»£èªæ³•:\n")
                for hint in r.dim_hints:
                    label_pairs = ', '.join(f'{lk}="{lv}"' for lk, lv in hint["labels"].items())
                    dim_key = f'{r.tenant_config and list(r.tenant_config.keys())[0].split("_critical")[0] or "metric"}{{{label_pairs}}}'
                    f.write(f'# "{dim_key}": "{list(r.tenant_config.values())[0]}"\n')
            f.write("\n")

    # --- platform-recording-rules.yaml (kubectl apply -f ready) ---
    all_recording_rules = []
    for r in results:
        if r.status == "unparseable":
            continue
        for rr in r.recording_rules:
            rule_with_comment = dict(rr)
            if r.agg_mode and r.agg_reason:
                # Add heuristic annotation as a comment-like field
                rule_with_comment['_comment'] = f"ğŸ¤– AI çŒœæ¸¬: {r.agg_mode} â€” {r.agg_reason}"
            all_recording_rules.append(rule_with_comment)

    with open(os.path.join(output_dir, "platform-recording-rules.yaml"), 'w', encoding='utf-8') as f:
        f.write("# ============================================================\n")
        f.write("# Platform Recording Rules\n")
        f.write("# åŠ å…¥ configmap-prometheus.yaml çš„ recording rule group ä¸­\n")
        f.write("# ============================================================\n\n")
        for r in results:
            if r.status == "unparseable":
                continue
            f.write(f"# --- {r.alert_name} ---\n")
            f.write(f"# ğŸ¤– AI çŒœæ¸¬: {r.agg_mode} â€” {r.agg_reason}\n")
            for rr in r.recording_rules:
                f.write(yaml.dump([rr], sort_keys=False, allow_unicode=True, default_flow_style=False))
            f.write("\n")

    # --- platform-alert-rules.yaml (kubectl apply -f ready) ---
    with open(os.path.join(output_dir, "platform-alert-rules.yaml"), 'w', encoding='utf-8') as f:
        f.write("# ============================================================\n")
        f.write("# Platform Dynamic Alert Rules\n")
        f.write("# åŠ å…¥ configmap-prometheus.yaml çš„ alerting rule group ä¸­\n")
        f.write("# ============================================================\n\n")
        for r in results:
            if r.status == "unparseable":
                continue
            f.write(f"# --- {r.alert_name} ---\n")
            alert_yaml = yaml.safe_dump(r.alert_rules, sort_keys=False, allow_unicode=True)
            f.write(alert_yaml)
            f.write("\n")

    # --- migration-report.txt ---
    perfect = [r for r in results if r.status == "perfect"]
    complex_rules = [r for r in results if r.status == "complex"]
    unparseable = [r for r in results if r.status == "unparseable"]

    with open(os.path.join(output_dir, "migration-report.txt"), 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("é·ç§»å ±å‘Š (Migration Report)\n")
        f.write("=" * 60 + "\n\n")
        f.write(f"ç¸½è¦å‰‡æ•¸: {len(results)}\n")
        f.write(f"  âœ… å®Œç¾è§£æ: {len(perfect)}\n")
        f.write(f"  âš ï¸  è¤‡é›œè¡¨é”å¼ (å·²è‡ªå‹•çŒœæ¸¬): {len(complex_rules)}\n")
        f.write(f"  ğŸš¨ ç„¡æ³•è§£æ (éœ€ LLM å”åŠ©): {len(unparseable)}\n\n")

        if perfect:
            f.write("-" * 40 + "\n")
            f.write("âœ… å®Œç¾è§£æçš„è¦å‰‡\n")
            f.write("-" * 40 + "\n")
            for r in perfect:
                f.write(f"  â€¢ {r.alert_name}: {r.agg_mode} ({r.agg_reason})\n")
            f.write("\n")

        if complex_rules:
            f.write("-" * 40 + "\n")
            f.write("âš ï¸  è¤‡é›œè¡¨é”å¼ â€” å·²è‡ªå‹•çŒœæ¸¬èšåˆæ¨¡å¼ï¼Œå»ºè­°äººå·¥ç¢ºèª\n")
            f.write("-" * 40 + "\n")
            for r in complex_rules:
                f.write(f"  â€¢ {r.alert_name}: {r.agg_mode} ({r.agg_reason})\n")
                if r.dim_hints:
                    f.write(f"    ğŸ“ ç¶­åº¦æ¨™ç±¤åµæ¸¬: {r.dim_hints}\n")
            f.write("\n")

        if unparseable:
            f.write("-" * 40 + "\n")
            f.write("ğŸš¨ ç„¡æ³•è‡ªå‹•è§£æ â€” è«‹å°‡ä»¥ä¸‹ LLM Prompt äº¤çµ¦ Claude è™•ç†\n")
            f.write("-" * 40 + "\n")
            for r in unparseable:
                f.write(f"\n### {r.alert_name} ###\n")
                f.write(r.llm_prompt)
                f.write("\n")

    return len(perfect), len(complex_rules), len(unparseable)


def print_dry_run(results):
    """Dry-run æ¨¡å¼: åƒ…åœ¨ STDOUT è¼¸å‡ºå ±å‘Šæ‘˜è¦ã€‚"""
    perfect = [r for r in results if r.status == "perfect"]
    complex_rules = [r for r in results if r.status == "complex"]
    unparseable = [r for r in results if r.status == "unparseable"]

    print(f"\n{'='*60}")
    print("ğŸ” Dry-Run é è¦½ (ä¸ç”¢ç”Ÿæª”æ¡ˆ)")
    print(f"{'='*60}\n")
    print(f"ç¸½è¦å‰‡æ•¸: {len(results)}")
    print(f"  âœ… å®Œç¾è§£æ: {len(perfect)}")
    print(f"  âš ï¸  è¤‡é›œè¡¨é”å¼ (è‡ªå‹•çŒœæ¸¬): {len(complex_rules)}")
    print(f"  ğŸš¨ ç„¡æ³•è§£æ (éœ€ LLM): {len(unparseable)}\n")

    for r in results:
        if r.status == "unparseable":
            print(f"  ğŸš¨ {r.alert_name}: ç„¡æ³•è‡ªå‹•è§£æ (éœ€ LLM å”åŠ©)")
        else:
            icon = "âœ…" if r.status == "perfect" else "âš ï¸"
            print(f"  {icon} {r.alert_name}: {r.agg_mode} â€” {r.agg_reason}")
            for k, v in r.tenant_config.items():
                print(f"     â†’ {k}: \"{v}\"")
            if r.dim_hints:
                print(f"     ğŸ“ ç¶­åº¦: {r.dim_hints}")
    print()


# ============================================================
# Main
# ============================================================

def main():
    parser = argparse.ArgumentParser(
        description="å‚³çµ± Prometheus è­¦å ±è¦å‰‡é·ç§»è¼”åŠ©å·¥å…· â€” è‡ªå‹•è½‰æ›ç‚ºå‹•æ…‹å¤šç§Ÿæˆ¶ä¸‰ä»¶å¥—"
    )
    parser.add_argument("input_file", help="å‚³çµ± Prometheus alert rules YAML æª”æ¡ˆ")
    parser.add_argument("-o", "--output-dir", default="migration_output",
                        help="è¼¸å‡ºç›®éŒ„ (é è¨­: migration_output)")
    parser.add_argument("--dry-run", action="store_true",
                        help="åƒ…é¡¯ç¤ºå ±å‘Šï¼Œä¸ç”¢ç”Ÿæª”æ¡ˆ")
    parser.add_argument("--interactive", action="store_true",
                        help="é‡åˆ°è¤‡é›œè¡¨é”å¼æ™‚äº’å‹•è©¢å•èšåˆæ¨¡å¼")
    args = parser.parse_args()

    try:
        with open(args.input_file, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
    except Exception as e:
        print(f"Error reading YAML file: {e}", file=sys.stderr)
        sys.exit(1)

    groups = data.get('groups', [])
    if not groups:
        print("No 'groups' found in YAML.")
        return

    # è™•ç†æ‰€æœ‰è¦å‰‡
    results = []
    for group in groups:
        rules = group.get('rules', [])
        for rule in rules:
            result = process_rule(rule, interactive=args.interactive)
            if result:
                results.append(result)

    if not results:
        print("No alert rules found to process.")
        return

    # è¼¸å‡º
    if args.dry_run:
        print_dry_run(results)
    else:
        n_perfect, n_complex, n_unparseable = write_outputs(results, args.output_dir)
        print(f"[âœ“] æˆåŠŸè§£æ {n_perfect + n_complex} æ¢è¦å‰‡ "
              f"(âœ… {n_perfect} å®Œç¾, âš ï¸ {n_complex} å·²çŒœæ¸¬)")
        if n_unparseable:
            print(f"[!] {n_unparseable} æ¢éœ€äººå·¥è™•ç† (LLM Prompt å·²å¯«å…¥å ±å‘Š)")
        print(f"ğŸ“ æª”æ¡ˆå·²è¼¸å‡ºè‡³ {args.output_dir}/")


if __name__ == "__main__":
    main()
